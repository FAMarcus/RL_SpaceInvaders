{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "RLNN-Space_Invaders_Train_GoogleColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59p9H46cXSdo"
      },
      "source": [
        "# 0. Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TimJOttHXSd3"
      },
      "source": [
        "!pip install tensorflow==2.3.1 gym keras-rl2 gym[atari]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wfr-vAGXj7L",
        "outputId": "8805026f-c62e-4a14-f79f-0f596d814d4f"
      },
      "source": [
        "!pip install gym gym[atari] keras-rl2 atari-py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 662 kB/s \n",
            "\u001b[?25hRequirement already satisfied: atari-py in /usr/local/lib/python3.7/dist-packages (0.2.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py) (1.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-rXj0tJhbsu",
        "outputId": "8c9d161c-a709-45ad-cf4b-3c23bccdbb8b"
      },
      "source": [
        "# Habilitar o acesso ao disco do Google Drive para leitura e escrita.\n",
        "# \n",
        "from google.colab import drive\n",
        "#drive.mount('drive')\n",
        "# Mount drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5CHL18ISdyB",
        "outputId": "33daa523-b9ae-4902-b118-e3a4911373fe"
      },
      "source": [
        "# Importando a ROM gravada no Google Drive\n",
        "!python -m atari_py.import_roms '/drive/My Drive/SpaceInvaders_ROMS/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copying space_invaders.bin from /drive/My Drive/SpaceInvaders_ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1jCVmSdSwE7",
        "outputId": "1321c1d6-7211-4f04-e0f0-1198d56df49b"
      },
      "source": [
        "# Verificando as ROMs da Atari disponíveis.\n",
        "import atari_py\n",
        "atari_py.list_games()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tetris', 'space_invaders']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrftRdlfXSd5"
      },
      "source": [
        "# 1. Test Random Environment with OpenAI Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3LpfVsUXSd7"
      },
      "source": [
        "import gym \n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6NWxnmxXSd9"
      },
      "source": [
        "# Carregando o ambiente para treino\n",
        "env = gym.make('SpaceInvaders-v0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki0v-5poXSd9"
      },
      "source": [
        "SpaceInvaders-v0\n",
        "\n",
        "Maximize your score in the Atari 2600 game SpaceInvaders.   \n",
        "In this environment, the observation is an RGB image of the screen, which is an array of shape (210, 160, 3).  \n",
        "Each action is repeatedly performed for a duration of kkk frames, where kkk is uniformly sampled from \\{2, 3, 4\\}.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SATVV6gnXSd_"
      },
      "source": [
        "height, width, channels = env.observation_space.shape\n",
        "actions = env.action_space.n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSh8Iyj4XSeA",
        "outputId": "3623df08-f109-4364-baf8-d8427bd23806"
      },
      "source": [
        "env.unwrapped.get_action_meanings()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EEfY9cmXSeF"
      },
      "source": [
        "## Esta rotina abre a janela do jogo e joga com comandos aleatórios. \n",
        "# episodes = 8\n",
        "# for episode in range(1, episodes+1):\n",
        "#     state = env.reset()\n",
        "#     done = False\n",
        "#     score = 0 \n",
        "    \n",
        "#     while not done:\n",
        "#         env.render()\n",
        "#         action = random.choice([0,1,2,3,4,5])\n",
        "#         n_state, reward, done, info = env.step(action)\n",
        "#         score+=reward\n",
        "#     print('Episode:{} Score:{}'.format(episode, score))\n",
        "# env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xGrTOCQXSeG"
      },
      "source": [
        "# 2. Create a Deep Learning Model with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYQVkEJxXSeH"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk7cSIP5XSeK"
      },
      "source": [
        "def build_model(height, width, channels, actions):\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu', input_shape=(3,height, width, channels)))\n",
        "    model.add(Convolution2D(64, (4,4), strides=(2,2), activation='relu'))\n",
        "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "    return model\n",
        "\n",
        "\n",
        "# model.add(\n",
        "# Convolution2D - Metodo para procurar diferenças nas imagens\n",
        "#(32 - Numero de filtros para detectar diferenças nas imagens\n",
        "#(8,8) - Tamanho da matriz em que o filtro será aplicado, \n",
        "# strides=(4,4) - Tamanho do passo em pixeis que a matriz filtro se desloca na imagem.\n",
        "# activation='relu', \n",
        "# input_shape=(3,height, width, channels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOQbtuE7XSeN"
      },
      "source": [
        "model = build_model(height, width, channels, actions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZORVlM_uXSeO",
        "outputId": "f0809d74-843e-4201-c451-5f89a703e5c4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 3, 51, 39, 32)     6176      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 3, 24, 18, 64)     32832     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 22, 16, 64)     36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 67584)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               34603520  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,812,326\n",
            "Trainable params: 34,812,326\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6vMk7tQXSeP"
      },
      "source": [
        "# 3. Build Agent with Keras-RL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgZsE4EKXSeP"
      },
      "source": [
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhCgDqtwXSeQ"
      },
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
        "    memory = SequentialMemory(limit=1000, window_length=3)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                  enable_dueling_network=True, dueling_type='avg', \n",
        "                   nb_actions=actions, nb_steps_warmup=1000\n",
        "                  )\n",
        "    return dqn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKHUS2LCntIM"
      },
      "source": [
        "# Modelo foi removido como solução ao problema de treino. \n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF429N7IokZf"
      },
      "source": [
        "model = build_model(height, width, channels, actions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyGzNapaXSeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf359ed-a0dd-4836-fac6-e266ed5ec3c6"
      },
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(Adam(lr=1e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-phWtDy_T-Ox"
      },
      "source": [
        "import time\n",
        "\n",
        "#Tic\n",
        "sys_start_time = time.perf_counter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipJl7HCOXSeR",
        "outputId": "912c51c0-2cdf-4b3a-f51d-990eb3f878dc"
      },
      "source": [
        "dqn.fit(env, nb_steps=5000, visualize=False, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 5000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  697/5000: episode: 1, duration: 19.996s, episode steps: 697, steps per second:  35, episode reward: 110.000, mean reward:  0.158 [ 0.000, 30.000], mean action: 2.433 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1427/5000: episode: 2, duration: 416.065s, episode steps: 730, steps per second:   2, episode reward: 185.000, mean reward:  0.253 [ 0.000, 30.000], mean action: 2.516 [0.000, 5.000],  loss: 355.002717, mean_q: -1.029197, mean_eps: 0.890785\n",
            " 2064/5000: episode: 3, duration: 607.559s, episode steps: 637, steps per second:   1, episode reward: 120.000, mean reward:  0.188 [ 0.000, 30.000], mean action: 2.457 [0.000, 5.000],  loss: 0.394675, mean_q: -2.931919, mean_eps: 0.842950\n",
            " 2795/5000: episode: 4, duration: 717.077s, episode steps: 731, steps per second:   1, episode reward: 225.000, mean reward:  0.308 [ 0.000, 30.000], mean action: 2.461 [0.000, 5.000],  loss: 0.909446, mean_q: -3.105091, mean_eps: 0.781390\n",
            " 3495/5000: episode: 5, duration: 682.278s, episode steps: 700, steps per second:   1, episode reward: 85.000, mean reward:  0.121 [ 0.000, 20.000], mean action: 2.377 [0.000, 5.000],  loss: 0.274312, mean_q: -3.039830, mean_eps: 0.716995\n",
            " 4074/5000: episode: 6, duration: 565.462s, episode steps: 579, steps per second:   1, episode reward: 20.000, mean reward:  0.035 [ 0.000, 10.000], mean action: 2.508 [0.000, 5.000],  loss: 0.199626, mean_q: -3.763132, mean_eps: 0.659440\n",
            " 4728/5000: episode: 7, duration: 640.839s, episode steps: 654, steps per second:   1, episode reward: 310.000, mean reward:  0.474 [ 0.000, 200.000], mean action: 2.376 [0.000, 5.000],  loss: 4.793540, mean_q: -2.910265, mean_eps: 0.603955\n",
            "done, took 3913.694 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef58d88790>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vwoz4imUJ0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceebd326-4bff-42e7-ecc3-9cc96983eaea"
      },
      "source": [
        "#Toc\n",
        "delta_t = time.perf_counter() - sys_start_time\n",
        "\n",
        "# Exibindo o tempo utilizado para o processo.\n",
        "print('\\n \\n')\n",
        "if delta_t > 3600:\n",
        "    delta_t = delta_t / 3600\n",
        "    print(\"Elapsed time: %.1f hours\" % ((delta_t)))\n",
        "elif delta_t > 60 and delta_t <= 3600:\n",
        "    delta_t = delta_t / 60\n",
        "    print(\"Elapsed time: %.1f min\" % ((delta_t)))\n",
        "else:\n",
        "    print(\"Elapsed time: %.1f s\" % ((delta_t)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \n",
            "\n",
            "Elapsed time: 1.1 hours\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29VUvCxIXSeS"
      },
      "source": [
        "# 4. Saving Agent to Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T71RVG3nXSeT"
      },
      "source": [
        "dqn.save_weights('/drive/My Drive/RL_weights/SpaceInvaders_5000.h5f')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}